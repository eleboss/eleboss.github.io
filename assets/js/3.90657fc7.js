(window.webpackJsonp=window.webpackJsonp||[]).push([[3],{253:function(e,t,n){"use strict";n.r(t);var o=n(0),a=Object(o.a)({},function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("div",{staticClass:"content"},[n("h1",{attrs:{id:"work"}},[e._v("Work")]),e._v(" "),n("p",[e._v("Here are some works of mine.\n\x3c!-- ----------------------------------------------------------------------------------------------------------------------- --\x3e")]),e._v(" "),n("h2",{attrs:{id:"research"}},[e._v("Research")]),e._v(" "),n("MarkdownCard",{attrs:{image:"/projects/normalization.png"}},[n("p",[n("strong",[e._v("Efficient Spatial-Temporal Normalization of SAE Representation for Event Camera")])]),e._v(" "),n("p",[e._v("In this work, we propose a highly efficient normalization method named chain normalization and an improved ordering strategy. By embedding the inherent nature of SAE, our method can not only runs fast but also reach the highest performance without manual parameter tuning. In the experiment, our algorithm can run significantly faster than the previous methods. To further validate the normalized results, we conduct object recognition experiments on two large event-based open datasets. Experimental results show that our method achieves the highest classification accuracy among other normalization methods.")]),e._v(" "),n("p",[e._v("["),n("a",{attrs:{href:"https://github.com/eleboss/chain",target:"_blank",rel:"noopener noreferrer"}},[e._v("Code"),n("OutboundLink")],1),e._v("] ["),n("a",{attrs:{href:"https://github.com/eleboss/eleboss.github.io/blob/master/nor.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Preprint"),n("OutboundLink")],1),e._v("]")])]),e._v(" "),n("MarkdownCard",{attrs:{image:"/projects/grasping.png"}},[n("p",[n("strong",[e._v("Toward Autonomous Rotation-Aware Unmanned Aerial Grasping")])]),e._v(" "),n("p",[n("strong",[e._v("S. Lin")]),e._v(", J. Wang, R. Peng, W. Yang.")]),e._v(" "),n("p",[e._v("In this work, we developed a vision-based autonomous UAM with a 3DoF robotic arm for rotational grasping and with a displacement compensation system for center of gravity compensation. And we proposed a novel detection approach called Rotation-SqueezeDet to enable rotation-aware grasping, this approach can give the target position and rotation angle in near real-time on Jetson TX2.")]),e._v(" "),n("p",[e._v("["),n("a",{attrs:{href:"https://github.com/eleboss/UAMmech",target:"_blank",rel:"noopener noreferrer"}},[e._v("Open-hardware"),n("OutboundLink")],1),e._v("], ["),n("a",{attrs:{href:"https://www.mdpi.com/1424-8220/19/10/2396",target:"_blank",rel:"noopener noreferrer"}},[e._v("Paper"),n("OutboundLink")],1),e._v("]")])]),e._v(" "),n("MarkdownCard",{attrs:{image:"/projects/tunneldrone.png"}},[n("p",[n("strong",[e._v("Development of an Intelligent Unmanned Aircraft System for Tunnel Inspection (Thesis, In progress)")])]),e._v(" "),n("p",[e._v("In this work, I developed a tunnel inspection system based on Pixhawk4 and DJI M100 drone. I Employed point cloud filters and RANSAC line fitting for tunnel perception. And I employed VINS-Mono for localization. With several lab members, I successfully conducted multiple autonomous inspections in the 280-meter long Luojia Shan tunnel.")])]),e._v(" "),n("MarkdownCard",{attrs:{image:"/projects/wisar.png"}},[n("p",[n("strong",[e._v("An Intelligent Unmanned Aircraft System for Wilderness Search and Rescue")])]),e._v(" "),n("p",[e._v("H. Yu, "),n("strong",[e._v("S. Lin")]),e._v(", J. Wang, K. Fu, W. Yang.")]),e._v(" "),n("p",[e._v("In this work, we developed a wilderness search and rescue (WiSAR) system based on DJI M100 Unmanned Aerial Vehicle (UAV) and a ground station to search and rescue the survivors in wild. We combined infrared and optical target detection to increase the detection speed and accuracy. And we used multiple sensors to make this system can autonomous avoiding obstructions and landing on mobile platform. To increase the detection accuracy of SSD, we adopted ResNet-101 as the base net. And trained it on the UAV-PP dataset. The actual flying test have been conducted in multiple situations to verify the feasibility of our WiSAR system. Paper accepted by "),n("em",[e._v("IMAV")]),e._v(" and method has been granted a patent.")]),e._v(" "),n("p",[e._v("["),n("a",{attrs:{href:"http://www.imavs.org/papers/2017/143_imav2017_proceedings.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Paper"),n("OutboundLink")],1),e._v("]")])]),e._v(" "),n("h2",{attrs:{id:"competition"}},[e._v("Competition")]),e._v(" "),n("MarkdownCard",{attrs:{image:"/icra.jpg"}},[n("p",[n("strong",[e._v("ICRA2018 DJI Robomaster AI Challenge")])]),e._v(" "),n("p",[e._v("W. He, "),n("strong",[e._v("S. Lin")]),e._v(", Q. Cui, R. Peng, J. Wang, H. Yu.")]),e._v(" "),n("p",[e._v("The ICRA 2018 DJI RoboMaster AI Challenge requires robots to drive and launch projectiles using artificial intelligence related technologies. Each team is required to build up to TWO autonomous AI robots to compete in a 5m Ã— 8m arena filled with various obstacles. To win, a team must defeat TWO AI robots presented by the RoboMaster Organizing Committee.")]),e._v(" "),n("p",[e._v("We won the "),n("strong",[e._v("Finalist Prize, Global Rank:6/70")]),e._v(" of "),n("a",{attrs:{href:"https://www.robomaster.com/en-US/robo/icra",target:"_blank",rel:"noopener noreferrer"}},[e._v("ICRA2018 DJI Robomaster AI Challenge"),n("OutboundLink")],1)]),e._v(" "),n("p",[e._v("Tech: "),n("em",[e._v("ROS C++ Python Tensorflow Solidworks")])])]),e._v(" "),n("h2",{attrs:{id:"project"}},[e._v("Project")]),e._v(" "),n("MarkdownCard",{attrs:{image:"/projects/micro.png"}},[n("p",[n("strong",[e._v("Smart Braille Reader")]),n("br"),e._v("\nProposed and build a universal braille reader. Designed PCB circuit can handle multiple braille touch units. Won the "),n("strong",[e._v("1"),n("sup",[e._v("st")]),e._v(" Prize")]),e._v(" of Microsoft Image Cup 2016 Global Students Technology Competition (China Round), Apr. 2016")]),e._v(" "),n("p",[e._v("Keywords: Touch Signal Processing, Azure Cloud, Multi-platform Data Transmission.")]),e._v(" "),n("p",[e._v("Tech: "),n("em",[e._v("PCB design C Python")])])]),e._v(" "),n("MarkdownCard",{attrs:{image:"/projects/multinode.jpeg"}},[n("p",[n("strong",[e._v("Multi-node Intelligent Access Control System")])]),e._v(" "),n("p",[e._v("A Multi-node Intelligent Access Control System based on BLE4.0, can automatically establish a communication link and exchange information without a wire. Knowing conditions of a building using data analysis.")]),e._v(" "),n("p",[e._v("Supported by:"),n("strong",[e._v("National Undergraduate Training Programs for Innovation(20000 CNY)")])]),e._v(" "),n("p",[e._v("Tech: "),n("em",[e._v("Android BLE4.0 Java C")])])]),e._v(" "),n("MarkdownCard",{attrs:{image:"/projects/airdetector.jpg"}},[n("p",[n("strong",[e._v("Air Quality Detector")])]),e._v(" "),n("p",[e._v("A Multi-node Intelligent Access Control System based on BLE4.0, can automatically establish a communication link and exchange information without a wire. Knowing conditions of a building using data analysis.")]),e._v(" "),n("p",[e._v("Tech: "),n("em",[e._v("PCB design BLE4.0 C")])])]),e._v(" "),n("MarkdownCard",{attrs:{image:"/projects/boat.jpg"}},[n("p",[n("strong",[e._v("A Sliver Ship")])]),e._v(" "),n("p",[n("strong",[e._v("Great oaks from little acorns grow.")])]),e._v(" "),n("p",[e._v("Tech: "),n("em",[e._v("My Intelligence + My Hand")])])])],1)},[],!1,null,null,null);t.default=a.exports}}]);